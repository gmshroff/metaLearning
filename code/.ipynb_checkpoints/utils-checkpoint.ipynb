{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmshroff/metaLearning2022/blob/main/code/utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A8BaRBTgaWW"
      },
      "source": [
        "# Dataset Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-X8UVWmgaWY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import sklearn.datasets as skds\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "from numpy import sin, pi\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision.datasets import MNIST\n",
        "import pathlib\n",
        "from PIL import Image\n",
        "from PIL.ImageOps import invert\n",
        "from IPython import display\n",
        "from time import sleep\n",
        "import pickle\n",
        "#hide_toggle('Imports')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g54Dz5lagaWZ"
      },
      "outputs": [],
      "source": [
        "def hide_toggle(x):\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2oNhdISgaWZ"
      },
      "source": [
        "Data generation routines will return a MyDS dataset class of type torch.utils.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wi-wlgxgaWZ"
      },
      "outputs": [],
      "source": [
        "class MyDS(Dataset):\n",
        "    def __init__(self, X,y):\n",
        "        self.samples = torch.Tensor(X)\n",
        "        self.labels = torch.LongTensor(y)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.samples[idx],self.labels[idx])\n",
        "#hide_toggle('Class MyDS')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz7gRG08gaWa"
      },
      "source": [
        "Generate data in $\\mathcal{R}^n$ with $n$ features, a number of classes, prescribed class separation and clusters per class. Return datasets for training and testing data and data-loader for training data using prescribed batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SY6lakkgaWa"
      },
      "outputs": [],
      "source": [
        "def euclideanDataset(n_samples=1000,n_classes=2,class_sep=2.0,n_features=5,batch_size=1):\n",
        "    X,y = skds.make_classification(n_samples=n_samples,n_classes=n_classes,\n",
        "                                   class_sep=class_sep,n_features=n_features, \n",
        "                                 n_informative=n_features,n_redundant=0,\n",
        "                                 n_repeated=0,n_clusters_per_class=1)\n",
        "    X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
        "    ds = MyDS(X_train,y_train)\n",
        "    ds_hold = MyDS(X_test,y_test)\n",
        "    dsloader = torch.utils.data.DataLoader(dataset=ds,batch_size=batch_size,shuffle=True)\n",
        "    return ds,ds_hold,dsloader\n",
        "#hide_toggle('Function euclideanDataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzusGlHJgaWb"
      },
      "source": [
        "Generate samples from a sinwave $a$ sin$(f\\pi t)$ of scale $a$, frequency $f$ at intervals $t = i \\delta t$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrmU5486gaWb"
      },
      "outputs": [],
      "source": [
        "class mysin():\n",
        "    def __init__(self,ampl = 1.0, freq=0.5, delta=0.1,phase=0.0):\n",
        "        self.f,self.d,self.a,self.p = freq, delta, ampl, phase\n",
        "        self.t = 0.0\n",
        "        return\n",
        "    def reset(self,t=0.0):\n",
        "        self.t = 0.0\n",
        "        return self.func()\n",
        "    def next(self):\n",
        "        val = self.func() \n",
        "        self.t += self.d\n",
        "        return val\n",
        "    def __call__(self,t):\n",
        "        old_t = self.t\n",
        "        self.t = t\n",
        "        val = self.func()\n",
        "        self.t = old_t\n",
        "        return val\n",
        "    def func(self):\n",
        "        return self.a * sin(pi*(self.f*self.t+self.p))\n",
        "    def series(self,n=10):\n",
        "        return np.array([self(t*self.d) for t in range(n)])\n",
        "    def set_phase(self,phase=0.0):\n",
        "        self.p = phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqdV_0XVgaWc"
      },
      "outputs": [],
      "source": [
        "def sinmix(X,m):\n",
        "    w = []\n",
        "    for i in range(X.shape[0]):\n",
        "        s = np.zeros(m)\n",
        "        for j in [2*k for k in range(int(X.shape[1]/2))]:\n",
        "            if (j/2)%2 == 0: s+=mysin(freq=X[i,j],phase=1.5,ampl=X[i,j+1]).series(m)\n",
        "            elif (j/2)%2 == 1: s+=np.tanh(mysin(freq=X[i,j],phase=1.5,ampl=X[i,j+1]).series(m))\n",
        "        w+=[s]\n",
        "    return np.array(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDAXVZcwgaWc"
      },
      "source": [
        "Random time-series = random frequency (f) and amplitude (a); random instance of a class = random phase (p) and length (l). We will generate n random clusters in 4D = {$f_1$,$a_1$,$f_2$,$a_2$}. For starters we will choose phase and length as constants and sum the two sine waves for each 4D vector to get a time series of fixed length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFrfu4sRgaWc"
      },
      "outputs": [],
      "source": [
        "def sinDataset(n_samples=10,n_classes=10,length=10,batch_size=1):\n",
        "    n_features = 4\n",
        "    X,y = skds.make_classification(n_samples=n_samples,n_classes=n_classes,\n",
        "                                   class_sep=4.0,n_features=n_features, \n",
        "                                 n_informative=n_features,n_redundant=0,\n",
        "                                 n_repeated=0,n_clusters_per_class=1)\n",
        "    X = X-X.min()+0.1\n",
        "    S = sinmix(X,length)\n",
        "    X_train,X_test,y_train,y_test = train_test_split(S,y)\n",
        "    ds = MyDS(X_train,y_train)\n",
        "    ds_hold = MyDS(X_test,y_test)\n",
        "    dsloader = torch.utils.data.DataLoader(dataset=ds,batch_size=batch_size,shuffle=False)\n",
        "    return ds,ds_hold,dsloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cM4_kjfigaWd"
      },
      "outputs": [],
      "source": [
        "def mnist_data(batch_size=32,frac=1.0,download=False):\n",
        "    trainset = MNIST('./data', train=True, download=download)\n",
        "    X_train = trainset.data.numpy().reshape(60000, -1).astype(np.float) / 255\n",
        "    n_train = int(X_train.shape[0]*frac)\n",
        "    X_train = X_train[0:n_train]\n",
        "    y_train = trainset.targets\n",
        "    y_train = y_train[0:n_train]\n",
        "    testset = MNIST('./data', train=False, download=download)\n",
        "    X_test = testset.data.numpy().reshape(10000, -1).astype(np.float) / 255\n",
        "    y_test = testset.targets\n",
        "    ds = MyDS(X_train,y_train)\n",
        "    ds_hold = MyDS(X_test,y_test)\n",
        "    dsloader = torch.utils.data.DataLoader(dataset=ds,batch_size=batch_size,shuffle=True)\n",
        "    return ds,ds_hold,dsloader\n",
        "#hide_toggle('Function mnist_data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEnqZeHcgaWd"
      },
      "source": [
        "Image data from NAR project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW1XDEb2gaWd"
      },
      "outputs": [],
      "source": [
        "def load_shape_map(save_dir: str) -> dict:\n",
        "    SHAPE_IMG_SIZE=(20,20)\n",
        "    \"\"\"Loads PIL images into a dictionary with shapes as keys\"\"\"\n",
        "    save_dir = pathlib.Path(save_dir)\n",
        "    img_dict = {}\n",
        "    for img_path in save_dir.glob(\"*.png\"):\n",
        "        img_dict[img_path.stem] = (\n",
        "            Image.open(img_path).convert(\"L\").resize(SHAPE_IMG_SIZE)\n",
        "        )\n",
        "    return img_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pjx5hq-KgaWd"
      },
      "outputs": [],
      "source": [
        "def remove_redundant_shapes(images):\n",
        "    redundant_shapes=['90circle','180circle','270circle','90square','180square','270square','0delta','90delta','180delta'\n",
        "                 '270delta','180theta','270theta','180x','270x','180z','270z']\n",
        "    images_temp=images.copy()\n",
        "    for key in images_temp.keys():\n",
        "        if key in redundant_shapes: images.pop(key,None)\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tayQ6_VPgaWd"
      },
      "outputs": [],
      "source": [
        "def image_data(batch_size=1,return_images=False,flatten=False):\n",
        "    images=load_shape_map('./images_rotate')\n",
        "    images=remove_redundant_shapes(images)\n",
        "    y=[]\n",
        "    X=[]\n",
        "    images_def=[]\n",
        "    names=[]\n",
        "    txfs=[]\n",
        "    mapping={}\n",
        "    for (i,k) in enumerate(list(images.keys())):\n",
        "        iDef,iTxL=deformed_images(images[k])\n",
        "        images_def+=iDef\n",
        "        if flatten==True: X+=[np.asarray(img).flatten() for img in iDef]\n",
        "        else: X+=[np.asarray(img) for img in iDef]\n",
        "        y+=[i]*len(iDef)\n",
        "        names+=[k]*len(iDef)\n",
        "        txfs+=iTxL\n",
        "        mapping[i]=k\n",
        "    #y=[k for (k,i) in enumerate(list(images.keys()))]\n",
        "    #X=[np.asarray(images[k]) for k in images.keys()]\n",
        "    X_train,X_test,y_train,y_test,images_train,images_test,names_train,names_test,tr_txL,te_txL = train_test_split(\n",
        "        X,y,images_def,names,txfs)\n",
        "    ds = MyDS(X_train,y_train)\n",
        "    ds_hold = MyDS(X_test,y_test)\n",
        "    dsloader = torch.utils.data.DataLoader(dataset=ds,batch_size=batch_size,shuffle=False)\n",
        "    if return_images==True:return ds,ds_hold,dsloader,images_train,images_test,names_train,names_test,mapping,tr_txL,te_txL\n",
        "    else: return ds,ds_hold,dsloader,mapping\n",
        "    #return X_train,X_test,y_train,y_test,images_train,images_test,names_train,names_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t2hHZaNgaWe"
      },
      "outputs": [],
      "source": [
        "# Deform an image via an affine transformation while retaining its size to fit in the same box\n",
        "def deform_image(t,a,b,c,d):    \n",
        "    def aff(a,b,d,e,z):\n",
        "        #x => (a(x-z)+b(y-z) = ax + by -az-bz\n",
        "        #y >= (d(x-z)+e(y-z) = dx + ey -dz-ez\n",
        "        return (a,b,-a*z-b*z+z,d,e,-d*z-e*z+z)\n",
        "    u=invert(t)\n",
        "    #u=u.transform((20,20),Image.AFFINE,aff(a,b,c,d,10))\n",
        "    u=u.transform((80,80),Image.AFFINE,(1, 0, -30, 0, 1,-30))\n",
        "    u=u.transform((80,80),Image.AFFINE,aff(a,b,c,d,40))\n",
        "    u=u.transform((80,80),Image.AFFINE,(1,0,30,0,1,30))\n",
        "    u=u.transform((20,20),Image.AFFINE,(1,0,0,0,1,0))\n",
        "    return u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLDqEResgaWe"
      },
      "outputs": [],
      "source": [
        "def deformed_images(t):\n",
        "    tL=[]\n",
        "    txL=[]\n",
        "    i=0\n",
        "    for sx in range(-10,11,1):\n",
        "        for sy in range(-10,11,1):\n",
        "            tL+=[deform_image(t,1,sx/10,sy/10,1)]\n",
        "            txL+=[(sx,sy)]\n",
        "            i+=1\n",
        "    return tL,txL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R44CKATggaWe"
      },
      "source": [
        "Save image data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_Wok5UIgaWe"
      },
      "outputs": [],
      "source": [
        "class ImageData():\n",
        "    def __init__(self,train_ds,test_ds,dloader,images_train,images_test,names_train,names_test,mapping):\n",
        "        self.train_ds=train_ds\n",
        "        self.test_ds=test_ds\n",
        "        self.images_train=images_train\n",
        "        self.images_test=images_test\n",
        "        self.names_train=names_train\n",
        "        self.names_test=names_test\n",
        "        self.dloader=dloader\n",
        "        self.mapping=mapping"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "oLtdJYoNgaWe"
      },
      "source": [
        "train_ds,test_ds,dloader,images_train,images_test,names_train,names_test,mapping,tr_txL,te_txL = image_data(flatten=True,\n",
        "                                                                                               return_images=True,batch_size=64)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "mG2on6UqgaWe"
      },
      "source": [
        "imageData=ImageData(train_ds,test_ds,dloader,images_train,images_test,names_train,names_test,mapping)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "2jdx1la_gaWe"
      },
      "source": [
        "%cd"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "E3IDW76HgaWe"
      },
      "source": [
        "with open('./DataLocal/course_data/image_data.pickle','wb') as f: pickle.dump(imageData,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B96tSSGtgaWe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "utils.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}